# ğŸš€ Taskity AI MCP Gemini Search

An AI-powered task search and prioritization system integrated with **Model Context Protocol (MCP)** and **OpenAI (Gemini-compatible LLM interface)**.

This project demonstrates advanced AI orchestration where natural language queries are converted into structured filters and executed via MCP tools.

---

## ğŸ”¥ Key Features

- Natural language task search
- AI-based filter extraction
- AI-powered task prioritization (0â€“100 scoring)
- MCP protocol integration (JSON-RPC)
- Dynamic tool invocation
- Client-side fallback filtering
- Production-ready FastAPI backend
- CORS-enabled frontend integration

---

## ğŸ§  System Architecture

```
Frontend (Search UI)
        â†“
FastAPI Backend
        â†“
AI Query Parser
        â†“
MCP Client (JSON-RPC)
        â†“
MCP Server Tools
        â†“
Task Data
```

---

## ğŸ›  Tech Stack

- Python 3.10+
- FastAPI
- OpenAI SDK
- MCP (Model Context Protocol)
- JSON-RPC
- Requests
- Python-dotenv
- Vanilla JS (Frontend)

---

## ğŸ§  AI Capabilities

### 1ï¸âƒ£ Natural Language Filter Extraction

Examples:

- â€œtasks by meghanaâ€
- â€œurgent tasks assigned to me due todayâ€
- â€œhigh priority tasks from john in public podâ€
- â€œoverdue tasks from public podâ€

Extracted filters:

```json
{
  "priority_labels": ["high"],
  "assigned_by": "john",
  "assigned_to": null,
  "due": null,
  "pod": "public",
  "only_overdue": false
}
```

---

### 2ï¸âƒ£ AI Task Prioritization

Each task receives:

- `ai_priority_score` (0â€“100)
- `ai_priority_rank`

Scoring considers:

- Urgency (due dates)
- Importance
- Status
- Recency
- Query relevance
- User context

---

## ğŸ” Environment Variables

Create a `.env` file:

```
OPENAI_API_KEY=your_key_here
MCP_URL=https://your-mcp-server.com
TASKITY_AUTH_TOKEN=your_token_here
MCP_PROTOCOL_VERSION=2025-03-26
```

Never commit `.env` to GitHub.

---

## ğŸš€ Running Locally

### 1ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run backend

```
uvicorn backend.app:app --reload
```

### 3ï¸âƒ£ Run frontend

```
cd frontend
python -m http.server 5500
```

Open:
```
http://127.0.0.1:5500
```

---

## ğŸ“¡ API Endpoints

### POST `/ai/search`

Natural language search â†’ MCP tool call â†’ AI prioritization

### POST `/ai/prioritize`

Direct AI-based prioritization of provided tasks

---

## ğŸ¯ Why This Project Is Impressive

This project demonstrates:

- AI agent-style architecture
- LLM-based filter extraction
- MCP protocol integration
- JSON-RPC communication
- Tool orchestration
- Production-safe fallbacks
- Backend engineering discipline

It combines:
- AI
- Systems design
- Protocol-level integration
- Real-world task automation

---

## ğŸ“Œ Future Improvements

- Authentication layer
- Streaming AI responses
- Async MCP support
- Caching layer
- Docker deployment
- Multi-user support

---

## ğŸ‘¨â€ğŸ’» Author

Yashu  
AI/ML Engineer | Backend Developer

---

## âš ï¸ Disclaimer

This project is for educational and portfolio purposes.
